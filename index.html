<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->



<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Home | VSDL</title>

<link rel="icon" href="/images/icon.jpg">

<meta name="title" content="">
<meta name="description" content="by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">

<meta property="og:title" content="">
<meta property="og:site_title" content="Vision and System Design Lab">
<meta property="og:description" content="by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">
<meta property="og:url" content="https://vsdl.hkust.edu.hk">
<meta property="og:image" content="/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="">
<meta property="twitter:description" content="by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">
<meta property="twitter:url" content="https://vsdl.hkust.edu.hk">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.jpg">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "",
    "description": "by the Greene Lab. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.",
    "headline": "",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/images/icon.jpg" }
    },
    "url": "https://vsdl.hkust.edu.hk"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="https://vsdl.hkust.edu.hk/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet">
</noscript>
  
  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/table-wrap.js"></script>

  <script src="/_scripts/tooltip.js"></script>
  
</head>

  <body>


<header class="background" style="--image: url('/images/background.webp');" data-dark="true" data-big>
  <a href="/" class="home">
    <img src="/images/logo3.svg" height="120">
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">Vision and System Design Lab</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
        <a href="/" data-tooltip="Home">
          Home
        </a>
        <a href="/publications/" data-tooltip="Published works">
          Publications
        </a>
        <a href="/research/" data-tooltip="Research of our group">
          Research
        </a>
        <a href="/demos/" data-tooltip="Demos, datasets, and more">
          Demos
        </a>
        <a href="/team/" data-tooltip="About our team">
          Team
        </a>
        <a href="/blog/" data-tooltip="Musings and miscellany">
          Blog
        </a>
        <a href="/contact/" data-tooltip="Email, address, and opening">
          Contact
        </a>
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->

  

  <section class="background" data-size="page">
    <h1 id="Who We Are">Who We Are</h1>

<p>Welcome to HKUST Vision and System Design Lab. The focus of our lab includes design, optimization and compression of artificial intelligence (AI) models, as well as architecture and design of AI chips/systems for energy-efficient training and inference of such AI models. Currently, we place strong focus on multimodal large foundation models for computer vision, vision-language, and medical applications. Our Lab also collaborates closely with InnoHK AI Chip Center for Smart Emerging Systems on co-design and co-optimization of AI systems across application, algorithm and hardware layers.</p>
  </section>


  <section class="background" data-size="page">
  <h2 id="highlights">News</h2>
    <div style="width: 1000px;height: 400px; overflow-x:hidden;">
      <li><b>October 2024.</b>&nbsp; <a href="#"><b>A 28nm 0.22μJ/Token Memory-Compute-Intensity-Aware CNN-Transformer Accelerator with Hybrid-Attention-Based Layer-Fusion and Cascaded Pruning for Semantic-Segmentation</b></a> is accepted by ISSCC 2025. In this paper, we propose a hybrid attention mechanism and KV-Weight-reused scheduler to fuse the layers between convolution and attention, and a cascaded feature map pruning method is introduced to achieve unified convolution-attention pruning. 
      </li>
      <li><b>September 2024.</b>&nbsp; Prof. Tim Cheng has been awarded the <a href="https://mp.weixin.qq.com/s/RomRBdXR6jBWLdbS-el9yA"><b>"CCF海外科技人物奖"</b></a> in recognition of his outstanding achievements in the field of computer science and his contributions to the advancement of computer science in China.
      </li>
      <li><b>September 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2407.08044"><b>RoLoRA: Finetuning Outlier-free Model with Rotation for Weight-Activation Quantization</b></a> is accepted by EMNLP 2024. This paper presents RoLoRA, an efficient LLM fine-tuning method preserving the outlier-free characteristics brought by rotation operations for effective weight-activation quantization.
      </li>
      <li><b>September 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2312.08901"><b>Fewer is More: Boosting LLM Reasoning with Reinforced Context Pruning</b></a> is accepted by EMNLP 2024. In this paper, we introduce a coarse-to-fine pruner to maximize the input of effective CoT examples, thereby improving LLM mathematical reasoning capability.
      </li>
      <li><b>September 2024.</b>&nbsp; <a href="https://openreview.net/forum?id=MHfoA0Qf6g"><b>Quantization Variation: A New Perspective on Training Transformers with Low-Bit Precision</b></a> is accepted by TMLR. In this paper, we provide an analysis of the underlying difficulty of transformer quantization in the view of variation. A multi-crop knowledge distillation-based quantization method is proposed.
      </li>
      <li><b>August 2024.</b>&nbsp; <a href="https://openreview.net/forum?id=4c2pZzG94y"><b>Efficient Quantization-aware Training with Adaptive Coreset Selection</b></a> is accepted by TMLR. This work introduces Quantization-Aware Adaptive Coreset Selection (ACS), a method that uses error vector and disagreement scores to select crucial training samples, significantly improving the training efficiency.
      </li>

      <li><b>August 2024.</b>&nbsp; <a href="#"><b>Labeled-to-Unlabeled Distribution Alignment for Partially-Supervised Multi-Organ Medical Image Segmentation</b></a> is accepted by Medical Image Analysis. In this paper, to address the problem of distribution mismatch, we propose a labeled-to-unlabeled distribution alignment framework that aligns feature distributions and enhances discriminative capability.
      </li>
      <li><b>August 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2303.06807"><b>Vessel-Promoted OCT to OCTA Image Translation by Heuristic Contextual Constraints</b></a> is accepted by Medical Image Analysis. We propose a novel framework, TransPro, that translates 3D OCT images into exclusive 3D OCTA images using an image translation pattern. Our main objective is to address two issues in existing image translation baselines, namely, the aimlessness in the translation process and incompleteness of the translated object.
      </li>
      <li><b>June 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2403.08407"><b>Iterative Online Image Synthesis via Diffusion Model for Imbalanced Classification</b></a> is accepted by MICCAI 2024. We introduce an Iterative Online Image Synthesis (IOIS) framework to address the class imbalance problem in medical image classification.
      </li>
      <li><b>June 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2403.09303"><b>Rethinking Autoencoders for Medical Anomaly Detection from A Theoretical Perspective</b></a> is accepted by MICCAI 2024. We for the first time provide a theoretical foundation for AE-based reconstruction methods in anomaly detection. By leveraging information theory, we elucidate the principles of these methods and reveal that the key to improving their performance lies in minimizing the information entropy of latent vectors. 
      </li>
      <li><b>May 2024.</b>&nbsp; <a href="#"><b>Aligning Medical Images with General Knowledge from Large Language Models</b></a> is early accepted by MICCAI 2024. We proposed ViP, a novel visual symptom-guided prompt learning framework for medical image analysis, which facilitates general knowledge transfer from CLIP. ViP mainly consists of two key components: a visual symptom generator and a dual-prompt network.
      </li>
      <li><b>May 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2106.06733"><b>LENAS: Learning-based Neural Architecture Search and Ensemble for 3D Radiotherapy Dose Prediction</b></a> is accepted by IEEE Transactions On Cybernetics. We proposed a novel learning-based ensemble approach named LENAS, which integrates neural architecture search with knowledge distillation for 3D radiotherapy dose prediction.
      </li>
      <li><b>April 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2402.09353"><b>DoRA: Weight-Decomposed Low-Rank Adaptation</b></a> is accepted by ICML 2024. We first introduced a novel weight decomposition analysis to investigate the inherent differences between FT and LoRA. Aiming to resemble the learning capacity of FT from the findings, we propose Weight-Decomposed LowRank Adaptation (DoRA).
      </li>
      <li><b>March 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2401.07437"><b>BoNuS: Boundary Mining for Nuclei Segmentation with Partial Point Labels</b></a> appears at IEEE Transactions on Medical Imaging. We proposed a novel boundary mining framework for nuclei segmentation, named BoNuS, which simultaneously learns nuclei interior and boundary information from the point labels. 
      </li>
      <li><b>March 2024.</b>&nbsp; <a href="https://arxiv.org/abs/2403.19591"><b>Genetic Quantization-Aware Approximation for Non-Linear Operations in Transformers</b></a> is accepted by DAC 2024. This paper proposed a genetic LUT-Approximation algorithm namely GQA-LUT that can automatically determine the parameters with quantization awareness. GQA-LUT enables the employment of INT8-based LUT-Approximation that achieves an area savings of 81.3~81.7% and a power reduction of 79.3~80.2% compared to the high-precision FP/INT 32 alternatives.
      </li>
      <li><b>December 2023.</b>&nbsp; <a href="#"><b>AdaP-CIM: Compute-in-Memory Based Neural Network Accelerator using Adaptive Posit</b></a> is accepted by DATE 2024.
      </li>
      <li><b>November 2023.</b>&nbsp; <a href="https://link.springer.com/article/10.1007/s11263-023-01928-1"><b>CAE-GReaT: Convolutional-Auxiliary Efficient Graph Reasoning Transformer for Dense Image Predictions</b></a> is accepted by International Journal of Computer Vision. We proposed an auxiliary and integrated network architecture, named Convolutional-Auxiliary Efficient Graph Reasoning Transformer, which joints strengths of both CNNs and ViT into a uniform framework.
      </li>
      <li><b>November 2023.</b>&nbsp; <a href="https://arxiv.org/abs/2207.01072"><b>Dynamic Sub-Cluster-Aware Network for Few-Shot Skin Disease Classification</b></a> is accepted by IEEE Transactions on Neural Networks and Learning Systems. This paper addresses the problem of few-shot skin disease classification by introducing a novel approach called the Sub-Cluster-Aware Network (SCAN) that enhances accuracy in diagnosing rare skin diseases.
      </li>
      <li><b>October 2023.</b>&nbsp; <a href="https://www.sciencedirect.com/science/article/pii/S1361841523001937"><b>Nuclei segmentation with point annotations from pathology images via self-supervised learning and co-training</b></a> is accepted by Medical Image Analysis. We proposed a weakly-supervised learning method for nuclei segmentation that only requires point annotations for training.
      </li>
      <li><b>July 2023.</b>&nbsp; <a href="https://arxiv.org/abs/2304.07519"><b>Compete to Win: Enhancing Pseudo Labels for Barely-supervised Medical Image Segmentation</b></a> is accepted by IEEE Transactions on Neural Networks and Learning Systems. We proposed a novel Compete-to-Win method to enhance the pseudo label quality. In contrast to directly using one model's predictions as pseudo labels, our key idea is that high-quality pseudo labels should be generated by comparing multiple confidence maps produced by different networks to select the most confident one.
      </li>
      <div class="button-wrapper">
        <a class="button" href="/publications/" data-tooltip="Read More" data-style="" aria-label="Read More">
          <i class="icon fa-solid fa-microscope"></i>
          <span>Read More</span>
        </a>
      </div>
    </div>
  </section>

  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<h2 id="highlights">Highlights</h2>

<!-- Publications -->
<div class="feature">
  <a href="/publications" class="feature-image" aria-label="Our Publications">
    <img src="/images/ourresearch.jpg" loading="lazy" alt="Our publications" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Our Publications</p>
    
    
<p>Our lab is at the forefront of cutting-edge AI research, covering a wide range of promising topics including AI chips/systems, compute-in-memory, electronic design automation, computer vision, vision-language, tiny machine learning, co-design, large foundational models, and medical image analysis.</p>

<div class="button-wrapper">
    <a class="button" href="/publications" data-style="bare" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>See our publications</span>
      
    </a>
  </div>


  </div>
</div>

<!-- research -->
<div class="feature" data-flip="">
  <a href="/research" class="feature-image" aria-label="Our Research">
    <img src="/images/ourprojects.webp" loading="lazy" alt="Our Research" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Our Research</p>
    
    
<p>Our research aims to make advanced AI technologies more effective and efficient, enabling everyone to enjoy the convenience and pleasure brought by these transformative technologies that will shape the future.</p>

<div class="button-wrapper">
    <a class="button" href="/research" data-style="bare" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>Browse our research</span>
      
    </a>
  </div>


  </div>
</div>

<!-- demos -->
<div class="feature">
  <a href="/demos" class="feature-image" aria-label="Our Demos">
    <img src="/images/ourdemos.webp" loading="lazy" alt="Our Demos" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Our Demos</p>
    
    
<p>Technology should never be limited to papers and slides. We strongly believe that our success in projects and demos is valuable and can drive potential solutions to practical problems.</p>

<div class="button-wrapper">
    <a class="button" href="/demos" data-style="bare" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>Watch our demos</span>
      
    </a>
  </div>


  </div>
</div>

<!-- team -->
<div class="feature" data-flip="">
  <a href="/team" class="feature-image" aria-label="Our Team">
    <img src="/images/ourteam.jpg" loading="lazy" alt="Our Team" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Our Team</p>
    
    
<p>We are a team of passionate researchers who are dedicated to pushing the forefront of artificial intelligence accelerator. We are committed to creating an inclusive environment for research and acknowledge the importance of diverse knowledge backgrounds in the discovery process.</p>

<div class="button-wrapper">
    <a class="button" href="/team" data-style="bare" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>Meet our team</span>
      
    </a>
  </div>


  </div>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/background.webp')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    © 2024
    Vision and System Design Lab
      |   Built with
    <a href="/team/">
     Team Members
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
